---
title: "Bayesian GLM Part1"
author: "Murray Logan"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: show
    collapse: no
    df_print: paged
    fig_caption: yes
    fig_height: 4
    fig_width: 4
    highlight: textmate
    theme: spacelab
    toc: yes
    toc_float: yes
    css: ../resources/style.css
  pdf_document:
    df_print: default
    fig_caption: yes
    fig_height: 4
    fig_width: 4
    highlight: tango
    latex_engine: xelatex
    number_sections: yes
    toc_depth: 2
  word_document:
    fig_caption: yes
    fig_height: 4
    fig_width: 4
    highlight: tango
    toc: yes
    toc_depth: 2
output_dir: "docs"
documentclass: article
fontsize: 12pt
mainfont: Arial
mathfont: LiberationMono
monofont: DejaVu Sans Mono
classoption: a4paper
bibliography: ../resources/references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```

# Preparations

Load the necessary libraries

```{r libraries, results='markdown', eval=TRUE}
library(rstanarm)   #for fitting models in STAN
library(coda)       #for diagnostics
library(bayesplot)  #for diagnostics
library(rstan)      #for interfacing with STAN
library(emmeans)    #for marginal means etc
library(broom)      #for tidying outputs
library(tidybayes)  #for more tidying outputs
library(ggeffects)  #for partial plots
library(tidyverse)  #for data wrangling etc
```

# Scenario

Here is an example from @Fowler-1998-1998. An agriculturalist was interested in the effects of fertilizer load on the yield of grass.  Grass seed was sown uniformly over an area and different quantities of commercial fertilizer were applied to each of ten 1 m<sup>2</sup> randomly located plots.  Two months later the grass from each plot was harvested, dried and weighed.  The data are in the file **fertilizer.csv** in the **data** folder.

![](../resources/turf.jpg)

| FERTILIZER   | YIELD   |
| ------------ | ------- |
| 25           | 84      |
| 50           | 80      |
| 75           | 90      |
| 100          | 154     |
| 125          | 148     |
| \...         | \...    |

---------------- ---------------------------------------------------
**FERTILIZER**:   Mass of fertilizer (g.m^-2^) - Predictor variable
**YIELD**:        Yield of grass (g.m^-2^) - Response variable
---------------- ---------------------------------------------------
 
 
The aim of the analysis is to investigate the relationship between fertilizer concentration and grass yield.

# Read in the data

```{r readData, results='markdown', eval=TRUE}
library(readr)
fert = read_csv('../data/fertilizer.csv', trim_ws=TRUE)
head(fert)
```



# Exploratory data analysis

Model formula:
$$
\begin{align}
y_i &\sim{} \mathcal{N}(\mu_i, \sigma^2)\\
\mu_i &= \beta_0 + \beta_1 x_i\\
\beta_0 &\sim{} \mathcal{N}(0,100)\\
\beta_1 &\sim{} \mathcal{N}(0,10)\\
\sigma &\sim{} \mathcal{cauchy}(0,5)\\
OR\\
\sigma &\sim{} \mathcal{Exp}(1)\\
\end{align}
$$

- Weakly informative priors
  A null prior says any value is possible. We don't almost never want that to be the case. If you allow your prior to be null, you can get nonsense.
  
- The prior on our intercept is a large distribution, centred around zero.
- We will check that they're not influential.
- a half cauchy is something you used to estimate variance, and it is cut in half because it assumes that it doesn't make sense to be less than zero.


# Fit the model

```{r}
summary(lm(YIELD ~ FERTILIZER, data = fert)) #Frequentist
```

[https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations]

```{r}
fert.rstanarm = stan_glm(YIELD ~ FERTILIZER, data = fert, iter = 5000, warmup = 500, chains = 3, thin = 2, refresh = 0) #after which iteration should i give you an update of where I'm up to. 0 means give me no updates.
```

```{r}
prior_summary(fert.rstanarm)
#Centred data helps to give the intercept some meaning, simplifies calculations
#Our priors for the intercept are a gaussian 0|10 and for the slope the priors are a gaussian 0|2.5.
#It didn't use a cauchy, but an exponential (rate=1)
```

First time you run the model:
```{r}
fert.rstanopt = stan_glm(YIELD ~ FERTILIZER, data = fert,
                         algorithm = 'optimizing') 
prior_summary(fert.rstanopt)
```

```{r}
fert.rstanarm = stan_glm(YIELD ~ FERTILIZER, data = fert, iter = 5000, 
                         warmup = 500, chains = 3, thin = 2, refresh = 0,
                         prior_intercept = normal(0,100,autoscale = F),
                         prior = normal(0,10, autoscale = F),
                         prior_aux = cauchy(0,5, autoscale = F))
posterior_vs_prior(fert.rstanarm, color_by = 'vs', group_by = T,
                   facet_args = list(scales = 'free_y'))
#you want the priors (in blue), to be larger that the posterior. This implies they were adequetly vague. If they're way to wide, you encourage it to sample wrong values
```

#Diagnostics
```{r}
stan_trace(fert.rstanarm)
#By default is giving us our main effects. We asked for three chains, which are in three colors. They are all random noise, as we want them. It would be bad if any of the colors are above/below. The chains are well mixed. It has replicated the entire likelihood.
```

```{r}
stan_dens(fert.rstanarm, separate_chains = T)
```

```{r}
#Diagnostics:

stan_trace(fert.rstanarm)
stan_dens(fert.rstanarm, separate_chains = T)
stan_ess(fert.rstanarm)
stan_ac(fert.rstanarm) #the chains were all well mixed and converged from a stable posterior
# converged -> they gave the same thing
# All Rhat values were below 1.05. If not, you have a lot of duplicates, rather than estimates.

pp_check(fert.rstanarm) # Each blue line represents one realisation of MCMC sample. They look very similar. If not, then the sampler wouldn’t be sampling the right thing.


#Posterior checks:
#pp_check(fert.rstanarm, plot_fun = ‘scatter’)
pp_check(fert.rstanarm, plot_fun = 'error_scatter_avg') 
# you want to see a scatter of points. If there’s a trend, then it means the model is better at predicting certain values, rather than others. It should be equally good at predicting at the whole range

#pp_check(fert.rstanarm, x = fert$FERTILIZER, plot_fun = ‘error_scatter_avg_vs_x’)

```


# Model investigation / hypothesis testing


```{r mcmcpvalue, results='markdown', eval=TRUE}
mcmcpvalue <- function(samp)
{
    ## elementary version that creates an empirical p-value for the
    ## hypothesis that the columns of samp have mean zero versus a
    ## general multivariate distribution with elliptical contours.
    
    ## differences from the mean standardized by the observed
    ## variance-covariance factor
    
    ## Note, I put in the bit for single terms
    if (length(dim(samp))==0) {
        std <- backsolve(chol(var(samp)),cbind(0, t(samp)) - mean(samp),transpose = TRUE)
        sqdist <- colSums(std * std)
        sum(sqdist[-1] > sqdist[1])/length(samp)
    }
    else {
        std <- backsolve(chol(var(samp)),cbind(0, t(samp)) - colMeans(samp),transpose = TRUE)
        sqdist <- colSums(std * std)
        sum(sqdist[-1] > sqdist[1])/nrow(samp)
    }
    
}

mcmcpvalue(as.matrix(fert.rstanarm)[,c("FERTILIZER")])
```

```{r}
fert.mcmc = as.matrix(fert.rstanarm)
nrow(fert.mcmc)
```
```{r}
head(fert.mcmc)
```
```{r}
mean(fert.mcmc[,'FERTILIZER']) #the mean of the column called FERTILIZER which was our slope. this is the same value we got from the summary table. This is also the best estimate of the slope
```

What is the probability that the slope is greater than 0.81? 50%
```{r}
sum(fert.mcmc[,'FERTILIZER']>0.811913)/6750
```

The probability that it is below? 50%
```{r}
sum(fert.mcmc[,'FERTILIZER']<0.811913)/6750
```


We can now reproduce the distribution:
```{r}
hist(fert.mcmc[,'FERTILIZER'])
#this is our distribution of all possible slopes
```


# Summary figures
```{r}
resid = resid(fert.rstanarm)
fit = fitted(fert.rstanarm)
ggplot() + geom_point(data = NULL, aes( y = resid, x = fit))
```

```{r}
ggpredict(fert.rstanarm) %>% plot
#its like plotting allEffects
```

```{r}
summary(fert.rstanarm)
#6750 samples (posterior sample size) 4500 per each chain, we thin by 2 (4500*3/2 = 6750)
#97.5 and 2.5 make up the 95% credibility intervals. We're 95% sure that the intercept is between 23.3 and 78.6. We're 50% sure it's between 42.5 and 60. The intercept still doesn't have any meaning tho.

#We can be 95% sure that the true slope is between 0.6 and 1.0. Because it doesn't include 0, 

#Diagnostics:
#Rhat values are less than 1.05 for each of the variables
#Out of 6750 posterior samples, 5592 of them are effective (unique/unrepeated). You want to have at least a 1000 unique samples, from which to get credibility samples.

#Estimates of variance
```

```{r}
tidyMCMC(fert.rstanarm, conf.int = T, conf.method = 'HPDinterval')
#the estimate is by default the mean, but you can change this
```


# References

                                 
